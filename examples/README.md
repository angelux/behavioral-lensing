# Behavioral Lensing Examples

Welcome! This folder contains a growing collection of practical examples demonstrating how **Behavioral Lensing** can be applied to elevate Large Language Model (LLM) outputs across various tasks, domains, and model contexts.

These examples aim to showcase the tangible difference Behavioral Lensing makes, particularly in tackling the 'final 20%' challenge where standard prompting often struggles to capture subtle context, deeper intent, or specific critical nuances. Explore these case studies to see how moving beyond direct instruction towards shaping the model's *interpretation* can lead to significantly more nuanced, aligned, and valuable results.

Each example provides a clear comparison and typically includes:

*   A description of the specific task and goal.
*   The prompt used for a standard/baseline approach (often a "best effort" traditional prompt).
*   The prompt incorporating Behavioral Lensing (using an Interpretive Framing Block - IFB).
*   A comparative analysis highlighting the differences in quality, nuance, and alignment with the core goal.

---

## Available Examples
*   **[Replicating Ebert's Critical Essence](./deep-replication-roger-ebert/)**  
    Focuses on replicating the deep critical *essence* of Roger Ebert's film reviews, going beyond simple style mimicry. This case study showcases how Behavioral Lensing can capture a nuanced analytical spirit and embody a specific critical philosophy ("how it is about it"), comparing IFB results against traditional prompting and Google Gemini's reasoning approach.
    
*   **[UX Evaluation â€“ Executive Brief](./ux-executive-brief-analysis/)**  
    Analyzes a mobile app concept brief from a User Experience (UX) perspective. This example compares a standard prompting approach against a Behavioral Lensing (IFB) approach across multiple models, demonstrating improved focus and actionable insight in specialized analysis.
